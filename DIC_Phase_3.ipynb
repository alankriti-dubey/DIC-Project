{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alankriti-dubey/DIC-Project/blob/main/DIC_Phase_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Required Libraries"
      ],
      "metadata": {
        "id": "nvgmZdPVuj7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, expr, count, when, lit, initcap\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
        "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RWXGojL6uiYv"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Spark Session"
      ],
      "metadata": {
        "id": "If5dgh3-upBG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Y8PJmLh0zvsL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Stop any active Spark session\n",
        "active_session = SparkSession.getActiveSession()\n",
        "if active_session is not None:\n",
        "    active_session.stop()\n",
        "\n",
        "# Create a new Spark session\n",
        "spark = SparkSession.builder.appName(\"DiabetesPrediction\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading dataset"
      ],
      "metadata": {
        "id": "vxL3sGsjwDrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from CSV file into a DataFrame\n",
        "df = spark.read.csv(\"diabetes_prediction_dataset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show the content of the DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l8SSTzb2-Ij",
        "outputId": "5cfc883c-f568-47c4-c492-483982c0907e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------------+-------------+---------------+-----+-----------+-------------------+--------+\n",
            "|gender| age|hypertension|heart_disease|smoking_history|  bmi|HbA1c_level|blood_glucose_level|diabetes|\n",
            "+------+----+------------+-------------+---------------+-----+-----------+-------------------+--------+\n",
            "|Female|80.0|           0|            1|          never|25.19|        6.6|                140|       0|\n",
            "|Female|54.0|           0|            0|        No Info|27.32|        6.6|                 80|       0|\n",
            "|  Male|28.0|           0|            0|          never|27.32|        5.7|                158|       0|\n",
            "|Female|36.0|           0|            0|        current|23.45|        5.0|                155|       0|\n",
            "|  Male|76.0|           1|            1|        current|20.14|        4.8|                155|       0|\n",
            "|Female|20.0|           0|            0|          never|27.32|        6.6|                 85|       0|\n",
            "|Female|44.0|           0|            0|          never|19.31|        6.5|                200|       1|\n",
            "|Female|79.0|           0|            0|        No Info|23.86|        5.7|                 85|       0|\n",
            "|  Male|42.0|           0|            0|          never|33.64|        4.8|                145|       0|\n",
            "|Female|32.0|           0|            0|          never|27.32|        5.0|                100|       0|\n",
            "|Female|53.0|           0|            0|          never|27.32|        6.1|                 85|       0|\n",
            "|Female|54.0|           0|            0|         former| 54.7|        6.0|                100|       0|\n",
            "|Female|78.0|           0|            0|         former|36.05|        5.0|                130|       0|\n",
            "|Female|67.0|           0|            0|          never|25.69|        5.8|                200|       0|\n",
            "|Female|76.0|           0|            0|        No Info|27.32|        5.0|                160|       0|\n",
            "|  Male|78.0|           0|            0|        No Info|27.32|        6.6|                126|       0|\n",
            "|  Male|15.0|           0|            0|          never|30.36|        6.1|                200|       0|\n",
            "|Female|42.0|           0|            0|          never|24.48|        5.7|                158|       0|\n",
            "|Female|42.0|           0|            0|        No Info|27.32|        5.7|                 80|       0|\n",
            "|  Male|37.0|           0|            0|           ever|25.72|        3.5|                159|       0|\n",
            "+------+----+------------+-------------+---------------+-----+-----------+-------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n"
      ],
      "metadata": {
        "id": "R9LXdK196tOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Dropping Duplicate Rows"
      ],
      "metadata": {
        "id": "nI1xdPH34S19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate rows\n",
        "df = df.dropDuplicates()\n",
        "\n",
        "# Show the count of records after dropping duplicates\n",
        "print(f\"Number of records after dropping duplicates: {df.count()}\")"
      ],
      "metadata": {
        "id": "Mzye3jId3Vj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1738d6e-3cbd-402f-b296-55355246e3dd"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after dropping duplicates: 96146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Converting Categorical Labels into a Numerical Format"
      ],
      "metadata": {
        "id": "hmkgc9gs4ZSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert categorical labels (e.g., 'gender') to numerical format\n",
        "indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_indexed\")\n",
        "df = indexer.fit(df).transform(df)\n",
        "\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"smoking_history\", outputCol=\"smoking_indexed\")\n",
        "df = indexer.fit(df).transform(df)\n",
        "\n",
        "# Show the transformed DataFrame\n",
        "print(df.select(\"smoking_indexed\").distinct().collect())\n",
        "df.select(\"gender_indexed\").distinct().collect()\n"
      ],
      "metadata": {
        "id": "T4zf8hb03zKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd08884-216a-4cdb-90c0-9763f9e226c9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(smoking_indexed=0.0), Row(smoking_indexed=1.0), Row(smoking_indexed=4.0), Row(smoking_indexed=3.0), Row(smoking_indexed=2.0), Row(smoking_indexed=5.0)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(gender_indexed=0.0), Row(gender_indexed=1.0), Row(gender_indexed=2.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Handling Outliers for the 'age' Column"
      ],
      "metadata": {
        "id": "QkqjAI4B4c5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure 'age' contains only integer values\n",
        "df = df.filter(col(\"age\").cast(\"int\").isNotNull())\n",
        "\n",
        "# Show the count of records after filtering\n",
        "print(f\"Number of records after handling age outliers: {df.count()}\")\n"
      ],
      "metadata": {
        "id": "7rwfGX0_4Nki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69682af-724d-40a8-bf37-6296fb7a29cd"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after handling age outliers: 96146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Handling Outliers for the 'BMI' Column Using IQR"
      ],
      "metadata": {
        "id": "Sjj-YLOA4g3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate Q1 and Q3\n",
        "Q1 = df.approxQuantile(\"bmi\", [0.25], 0.01)[0]\n",
        "Q3 = df.approxQuantile(\"bmi\", [0.75], 0.01)[0]\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Calculate outlier boundaries\n",
        "lower_limit = Q1 - 1.5 * IQR\n",
        "upper_limit = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filter rows that are within the acceptable range\n",
        "df = df.filter((col(\"bmi\") >= lower_limit) & (col(\"bmi\") <= upper_limit))\n",
        "\n",
        "# Show the filtered DataFrame\n",
        "df.select(\"bmi\").show(5)"
      ],
      "metadata": {
        "id": "bNoEH4eg4oJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6142bf-0904-4b6c-f7b5-ed1dd77d2478"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|  bmi|\n",
            "+-----+\n",
            "|27.32|\n",
            "|27.32|\n",
            "| 21.7|\n",
            "|20.47|\n",
            "| 31.4|\n",
            "+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Filtering Rows with Invalid Biological Values"
      ],
      "metadata": {
        "id": "MLNtKZMO4sDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter((col(\"age\") > 1) & (col(\"bmi\") > 10) & (col(\"blood_glucose_level\") >= 80))\n",
        "\n",
        "# Show the filtered DataFrame\n",
        "df.select(\"age\", \"bmi\", \"blood_glucose_level\").show(5)"
      ],
      "metadata": {
        "id": "cHx7kK_Q4xwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870e19fc-ea5c-4b7c-bf42-066b1cbd9205"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-------------------+\n",
            "| age|  bmi|blood_glucose_level|\n",
            "+----+-----+-------------------+\n",
            "|21.0|27.32|                126|\n",
            "|26.0|27.32|                100|\n",
            "|49.0| 21.7|                158|\n",
            "|24.0|20.47|                100|\n",
            "|53.0| 31.4|                 85|\n",
            "+----+-----+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Checking for Inconsistent Data in Categorical Column"
      ],
      "metadata": {
        "id": "9_DguciE5AQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.withColumn(\"smoking_history\", initcap(col(\"smoking_history\")))\n",
        "\n",
        "# Show the transformed DataFrame\n",
        "df.select(\"smoking_history\").show(5)"
      ],
      "metadata": {
        "id": "CaTT_vHn5A1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c373a8cf-7db7-41b1-af0e-d6370eadac47"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|smoking_history|\n",
            "+---------------+\n",
            "|          Never|\n",
            "|          Never|\n",
            "|          Never|\n",
            "|         Former|\n",
            "|          Never|\n",
            "+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Handling missing values"
      ],
      "metadata": {
        "id": "bLE-EXGV5QdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Calculate the mode of 'smoking_history'\n",
        "mode_value = df.groupBy(\"smoking_history\").count().orderBy(col(\"count\").desc()).first()[0]\n",
        "\n",
        "# Replace 'No info' with the mode value\n",
        "df = df.withColumn(\"smoking_history\", when(col(\"smoking_history\") == \"No info\", lit(mode_value)).otherwise(col(\"smoking_history\")))\n",
        "\n",
        "# Show the modified DataFrame\n",
        "df.select(\"smoking_history\").show(5)"
      ],
      "metadata": {
        "id": "ct38yUiV5AiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c39f3c-045c-4982-a2af-e7a971f06a84"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|smoking_history|\n",
            "+---------------+\n",
            "|          Never|\n",
            "|          Never|\n",
            "|          Never|\n",
            "|         Former|\n",
            "|          Never|\n",
            "+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Normalizing values"
      ],
      "metadata": {
        "id": "T-CWZhtd5bHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assemble columns into a vector\n",
        "assembler = VectorAssembler(inputCols=[\"blood_glucose_level\", \"HbA1c_level\"], outputCol=\"features\")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Apply StandardScaler\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "scaler_model = scaler.fit(df)\n",
        "df = scaler_model.transform(df)\n",
        "\n",
        "# Show the scaled features\n",
        "df.select(\"scaled_features\").show(5)"
      ],
      "metadata": {
        "id": "sjxWMsCI5hBM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2caf1af5-99cb-481f-e98d-1cb3ebbbec80"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|     scaled_features|\n",
            "+--------------------+\n",
            "|[-0.2904463527940...|\n",
            "|[-0.9344938505553...|\n",
            "|[0.50222749060444...|\n",
            "|[-0.9344938505553...|\n",
            "|[-1.3060597146483...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Dropping Null Values"
      ],
      "metadata": {
        "id": "1ZfZCZJE5mj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with null values\n",
        "df = df.na.drop()\n",
        "\n",
        "# Show the count of records after dropping nulls\n",
        "print(f\"Number of records after dropping nulls: {df.count()}\")"
      ],
      "metadata": {
        "id": "RInWXabq5sfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8848884d-2b69-49dd-9447-0f932db6c9c5"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after dropping nulls: 89595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Feature Engineering"
      ],
      "metadata": {
        "id": "FRKoofDY5vaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define BMI categories\n",
        "df = df.withColumn(\"bmi_category\",\n",
        "                   when((col(\"bmi\") > 0) & (col(\"bmi\") <= 18.5), \"Underweight\")\n",
        "                   .when((col(\"bmi\") > 18.5) & (col(\"bmi\") <= 24.9), \"Normal\")\n",
        "                   .when((col(\"bmi\") > 24.9) & (col(\"bmi\") <= 29.9), \"Overweight\")\n",
        "                   .when((col(\"bmi\") > 29.9), \"Obese\"))\n",
        "\n",
        "# Show the categorized BMI column\n",
        "df.select(\"bmi\", \"bmi_category\").show(5)"
      ],
      "metadata": {
        "id": "FMG6FePn50Tb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338e9e01-ff9d-443d-ebfb-de3c299a35ac"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+\n",
            "|  bmi|bmi_category|\n",
            "+-----+------------+\n",
            "|27.32|  Overweight|\n",
            "|27.32|  Overweight|\n",
            "| 21.7|      Normal|\n",
            "|20.47|      Normal|\n",
            "| 31.4|       Obese|\n",
            "+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "Do25OFrl57HQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "722e6ef5-c107-44ce-b960-94dad68f0abf"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[gender: string, age: double, hypertension: int, heart_disease: int, smoking_history: string, bmi: double, HbA1c_level: double, blood_glucose_level: int, diabetes: int, gender_indexed: double, smoking_indexed: double, features: vector, scaled_features: vector, bmi_category: string]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithms/Visualizations"
      ],
      "metadata": {
        "id": "TK6_gxzxpYOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the Dataset"
      ],
      "metadata": {
        "id": "Z5QkJoNQqFbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assembling features\n",
        "feature_cols = [\"gender_indexed\", \"age\", \"hypertension\", \"heart_disease\", \"smoking_indexed\", \"bmi\", \"HbA1c_level\", \"blood_glucose_level\"]\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Selecting final dataset\n",
        "final_data = df.select(col(\"features\"), col(\"diabetes\").alias(\"label\"))\n",
        "\n",
        "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=1234)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Ozbemm-TqH_J",
        "outputId": "b8e15e93-0a3e-4d3b-85a2-ffb24ef077e6"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "Output column features already exists.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-018b3ce532ab>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeature_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"gender_indexed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"age\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hypertension\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"heart_disease\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"smoking_indexed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bmi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HbA1c_level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"blood_glucose_level\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0massembler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorAssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Selecting final dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: Output column features already exists."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Logistic Regression"
      ],
      "metadata": {
        "id": "jaUEkXuHphI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initializing Logistic Regression model\n",
        "logistic_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# Training the model\n",
        "logistic_model = logistic_reg.fit(train_data)\n",
        "\n",
        "# Evaluating on test data\n",
        "predictions = logistic_model.transform(test_data)\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()\n"
      ],
      "metadata": {
        "id": "FyuYe-fppncC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating Model Performance"
      ],
      "metadata": {
        "id": "hRt1jtILtYCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Accuracy"
      ],
      "metadata": {
        "id": "AWSrC31Gt1DF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "5zimPquEttba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrix"
      ],
      "metadata": {
        "id": "2E68cXiwt_ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "conf_matrix = predictions.groupBy(\"label\", \"prediction\").count()\n",
        "conf_matrix.show()"
      ],
      "metadata": {
        "id": "K1RkWQyQuCxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix_pd = conf_matrix.toPandas().pivot(index='label', columns='prediction', values='count').fillna(0)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_pd, annot=True, fmt=\"f\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "U7u38eYtuH5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AUC-ROC"
      ],
      "metadata": {
        "id": "dYMuQwWGwrXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"AUC: {auc}\")\n"
      ],
      "metadata": {
        "id": "XWRgAxTctMgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Decision Tree"
      ],
      "metadata": {
        "id": "TIq5xv_3szd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initializing Decision Tree model\n",
        "decision_tree = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# Training the model\n",
        "dt_model = decision_tree.fit(train_data)\n",
        "\n",
        "# Evaluating on test data\n",
        "predictions = dt_model.transform(test_data)\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()\n"
      ],
      "metadata": {
        "id": "O2bb3pvLs28p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating Model Performance"
      ],
      "metadata": {
        "id": "BKKWybQGtgEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Accuracy"
      ],
      "metadata": {
        "id": "T4CmgC_RwjmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "ZcCNhIrowQPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "RPpr24MZwlxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "conf_matrix = predictions.groupBy(\"label\", \"prediction\").count()\n",
        "conf_matrix.show()\n",
        "\n",
        "conf_matrix_pd = conf_matrix.toPandas().pivot(index='label', columns='prediction', values='count').fillna(0)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_pd, annot=True, fmt=\"f\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kqpmj2MHwfqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"AUC: {auc}\")"
      ],
      "metadata": {
        "id": "fCwD5WcltQaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Random Forest"
      ],
      "metadata": {
        "id": "DjXeyfMNs8bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initializing Random Forest model\n",
        "random_forest = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=10)\n",
        "\n",
        "# Training the model\n",
        "rf_model = random_forest.fit(train_data)\n",
        "\n",
        "# Evaluating on test data\n",
        "predictions = rf_model.transform(test_data)\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()\n"
      ],
      "metadata": {
        "id": "-TLR4DaUtACx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating Model Performance\n"
      ],
      "metadata": {
        "id": "ZGJiO9wAth2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"AUC: {auc}\")"
      ],
      "metadata": {
        "id": "RKDv7RD_tTm9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}