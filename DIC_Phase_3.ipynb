{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVj/xFNb8VQiIbHfSEOrvW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alankriti-dubey/DIC-Project/blob/main/DIC_Phase_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8PJmLh0zvsL"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Stop any active Spark session\n",
        "active_session = SparkSession.getActiveSession()\n",
        "if active_session is not None:\n",
        "    active_session.stop()\n",
        "\n",
        "# Create a new Spark session\n",
        "spark = SparkSession.builder.appName(\"DiabetesPrediction\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from CSV file into a DataFrame\n",
        "df = spark.read.csv(\"diabetes_prediction_dataset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show the content of the DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l8SSTzb2-Ij",
        "outputId": "993bcf1f-b694-4530-a540-9018fd552d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------------+-------------+---------------+-----+-----------+-------------------+--------+\n",
            "|gender| age|hypertension|heart_disease|smoking_history|  bmi|HbA1c_level|blood_glucose_level|diabetes|\n",
            "+------+----+------------+-------------+---------------+-----+-----------+-------------------+--------+\n",
            "|Female|80.0|           0|            1|          never|25.19|        6.6|                140|       0|\n",
            "|Female|54.0|           0|            0|        No Info|27.32|        6.6|                 80|       0|\n",
            "|  Male|28.0|           0|            0|          never|27.32|        5.7|                158|       0|\n",
            "|Female|36.0|           0|            0|        current|23.45|        5.0|                155|       0|\n",
            "|  Male|76.0|           1|            1|        current|20.14|        4.8|                155|       0|\n",
            "|Female|20.0|           0|            0|          never|27.32|        6.6|                 85|       0|\n",
            "|Female|44.0|           0|            0|          never|19.31|        6.5|                200|       1|\n",
            "|Female|79.0|           0|            0|        No Info|23.86|        5.7|                 85|       0|\n",
            "|  Male|42.0|           0|            0|          never|33.64|        4.8|                145|       0|\n",
            "|Female|32.0|           0|            0|          never|27.32|        5.0|                100|       0|\n",
            "|Female|53.0|           0|            0|          never|27.32|        6.1|                 85|       0|\n",
            "|Female|54.0|           0|            0|         former| 54.7|        6.0|                100|       0|\n",
            "|Female|78.0|           0|            0|         former|36.05|        5.0|                130|       0|\n",
            "|Female|67.0|           0|            0|          never|25.69|        5.8|                200|       0|\n",
            "|Female|76.0|           0|            0|        No Info|27.32|        5.0|                160|       0|\n",
            "|  Male|78.0|           0|            0|        No Info|27.32|        6.6|                126|       0|\n",
            "|  Male|15.0|           0|            0|          never|30.36|        6.1|                200|       0|\n",
            "|Female|42.0|           0|            0|          never|24.48|        5.7|                158|       0|\n",
            "|Female|42.0|           0|            0|        No Info|27.32|        5.7|                 80|       0|\n",
            "|  Male|37.0|           0|            0|           ever|25.72|        3.5|                159|       0|\n",
            "+------+----+------------+-------------+---------------+-----+-----------+-------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "R9LXdK196tOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Dropping Duplicate Rows"
      ],
      "metadata": {
        "id": "nI1xdPH34S19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate rows\n",
        "df = df.dropDuplicates()\n",
        "\n",
        "# Show the count of records after dropping duplicates\n",
        "print(f\"Number of records after dropping duplicates: {df.count()}\")"
      ],
      "metadata": {
        "id": "Mzye3jId3Vj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97cd9d79-9bbf-4662-b4bd-06da1f495094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after dropping duplicates: 96146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Converting Categorical Labels into a Numerical Format"
      ],
      "metadata": {
        "id": "hmkgc9gs4ZSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Convert categorical labels (e.g., 'gender') to numerical format\n",
        "indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_indexed\")\n",
        "df = indexer.fit(df).transform(df)\n",
        "\n",
        "# Show the transformed DataFrame\n",
        "df.select(\"gender\", \"gender_indexed\").show(5)\n"
      ],
      "metadata": {
        "id": "T4zf8hb03zKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df6b049-7bce-483c-a75a-767477497cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------+\n",
            "|gender|gender_indexed|\n",
            "+------+--------------+\n",
            "|Female|           0.0|\n",
            "|  Male|           1.0|\n",
            "|Female|           0.0|\n",
            "|Female|           0.0|\n",
            "|Female|           0.0|\n",
            "+------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Handling Outliers for the 'age' Column"
      ],
      "metadata": {
        "id": "QkqjAI4B4c5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Ensure 'age' contains only integer values\n",
        "df = df.filter(col(\"age\").cast(\"int\").isNotNull())\n",
        "\n",
        "# Show the count of records after filtering\n",
        "print(f\"Number of records after handling age outliers: {df.count()}\")\n"
      ],
      "metadata": {
        "id": "7rwfGX0_4Nki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f95f65-4ba6-423d-b41c-e89b9bf2aa2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after handling age outliers: 96146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Handling Outliers for the 'BMI' Column Using IQR"
      ],
      "metadata": {
        "id": "Sjj-YLOA4g3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "# Calculate Q1 and Q3\n",
        "Q1 = df.approxQuantile(\"bmi\", [0.25], 0.01)[0]\n",
        "Q3 = df.approxQuantile(\"bmi\", [0.75], 0.01)[0]\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Calculate outlier boundaries\n",
        "lower_limit = Q1 - 1.5 * IQR\n",
        "upper_limit = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filter rows that are within the acceptable range\n",
        "df = df.filter((col(\"bmi\") >= lower_limit) & (col(\"bmi\") <= upper_limit))\n",
        "\n",
        "# Show the filtered DataFrame\n",
        "df.select(\"bmi\").show(5)"
      ],
      "metadata": {
        "id": "bNoEH4eg4oJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1cab79-f485-4149-fc44-898444446a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|  bmi|\n",
            "+-----+\n",
            "|27.32|\n",
            "|27.32|\n",
            "| 21.7|\n",
            "|20.47|\n",
            "| 31.4|\n",
            "+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Filtering Rows with Invalid Biological Values"
      ],
      "metadata": {
        "id": "MLNtKZMO4sDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter((col(\"age\") > 1) & (col(\"bmi\") > 10) & (col(\"blood_glucose_level\") >= 80))\n",
        "\n",
        "# Show the filtered DataFrame\n",
        "df.select(\"age\", \"bmi\", \"blood_glucose_level\").show(5)"
      ],
      "metadata": {
        "id": "cHx7kK_Q4xwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c691595-582b-4d69-dc94-93912b380644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-------------------+\n",
            "| age|  bmi|blood_glucose_level|\n",
            "+----+-----+-------------------+\n",
            "|21.0|27.32|                126|\n",
            "|26.0|27.32|                100|\n",
            "|49.0| 21.7|                158|\n",
            "|24.0|20.47|                100|\n",
            "|53.0| 31.4|                 85|\n",
            "+----+-----+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Checking for Inconsistent Data in Categorical Column"
      ],
      "metadata": {
        "id": "9_DguciE5AQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import initcap\n",
        "\n",
        "df = df.withColumn(\"smoking_history\", initcap(col(\"smoking_history\")))\n",
        "\n",
        "# Show the transformed DataFrame\n",
        "df.select(\"smoking_history\").show(5)"
      ],
      "metadata": {
        "id": "CaTT_vHn5A1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09579769-7382-4711-99bb-a90844fe7e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|smoking_history|\n",
            "+---------------+\n",
            "|          Never|\n",
            "|          Never|\n",
            "|          Never|\n",
            "|         Former|\n",
            "|          Never|\n",
            "+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Handling missing values"
      ],
      "metadata": {
        "id": "bLE-EXGV5QdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, count, when, lit\n",
        "\n",
        "# Calculate the mode of 'smoking_history'\n",
        "mode_value = df.groupBy(\"smoking_history\").count().orderBy(col(\"count\").desc()).first()[0]\n",
        "\n",
        "# Replace 'No info' with the mode value\n",
        "df = df.withColumn(\"smoking_history\", when(col(\"smoking_history\") == \"No info\", lit(mode_value)).otherwise(col(\"smoking_history\")))\n",
        "\n",
        "# Show the modified DataFrame\n",
        "df.select(\"smoking_history\").show(5)"
      ],
      "metadata": {
        "id": "ct38yUiV5AiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a33402-f154-41e5-9e52-e8605dbdba5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|smoking_history|\n",
            "+---------------+\n",
            "|          Never|\n",
            "|          Never|\n",
            "|          Never|\n",
            "|         Former|\n",
            "|          Never|\n",
            "+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Normalizing values"
      ],
      "metadata": {
        "id": "T-CWZhtd5bHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "\n",
        "# Assemble columns into a vector\n",
        "assembler = VectorAssembler(inputCols=[\"blood_glucose_level\", \"HbA1c_level\"], outputCol=\"features\")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Apply StandardScaler\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "scaler_model = scaler.fit(df)\n",
        "df = scaler_model.transform(df)\n",
        "\n",
        "# Show the scaled features\n",
        "df.select(\"scaled_features\").show(5)"
      ],
      "metadata": {
        "id": "sjxWMsCI5hBM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6096f8ff-2305-4bdc-ee30-ad9d9cdbe8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|     scaled_features|\n",
            "+--------------------+\n",
            "|[-0.2904463527940...|\n",
            "|[-0.9344938505553...|\n",
            "|[0.50222749060444...|\n",
            "|[-0.9344938505553...|\n",
            "|[-1.3060597146483...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Dropping Null Values"
      ],
      "metadata": {
        "id": "1ZfZCZJE5mj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with null values\n",
        "df = df.na.drop()\n",
        "\n",
        "# Show the count of records after dropping nulls\n",
        "print(f\"Number of records after dropping nulls: {df.count()}\")"
      ],
      "metadata": {
        "id": "RInWXabq5sfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d5f352-050a-4714-b8f7-ed91700e45a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after dropping nulls: 89595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Feature Engineering"
      ],
      "metadata": {
        "id": "FRKoofDY5vaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Define BMI categories\n",
        "df = df.withColumn(\"bmi_category\",\n",
        "                   when((col(\"bmi\") > 0) & (col(\"bmi\") <= 18.5), \"Underweight\")\n",
        "                   .when((col(\"bmi\") > 18.5) & (col(\"bmi\") <= 24.9), \"Normal\")\n",
        "                   .when((col(\"bmi\") > 24.9) & (col(\"bmi\") <= 29.9), \"Overweight\")\n",
        "                   .when((col(\"bmi\") > 29.9), \"Obese\"))\n",
        "\n",
        "# Show the categorized BMI column\n",
        "df.select(\"bmi\", \"bmi_category\").show(5)"
      ],
      "metadata": {
        "id": "FMG6FePn50Tb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7116073-8fc3-4f17-d10a-720ea2777f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+\n",
            "|  bmi|bmi_category|\n",
            "+-----+------------+\n",
            "|27.32|  Overweight|\n",
            "|27.32|  Overweight|\n",
            "| 21.7|      Normal|\n",
            "|20.47|      Normal|\n",
            "| 31.4|       Obese|\n",
            "+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "Do25OFrl57HQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfc0176-ff26-4a24-bed9-e7bcee5e7273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[gender: string, age: double, hypertension: int, heart_disease: int, smoking_history: string, bmi: double, HbA1c_level: double, blood_glucose_level: int, diabetes: int, gender_indexed: double, features: vector, scaled_features: vector, bmi_category: string]\n"
          ]
        }
      ]
    }
  ]
}