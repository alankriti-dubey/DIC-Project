{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alankriti-dubey/DIC-Project/blob/main/DIC_Phase_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y8PJmLh0zvsL"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Stop any active Spark session\n",
        "active_session = SparkSession.getActiveSession()\n",
        "if active_session is not None:\n",
        "    active_session.stop()\n",
        "\n",
        "# Create a new Spark session\n",
        "spark = SparkSession.builder.appName(\"DiabetesPrediction\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from CSV file into a DataFrame\n",
        "df = spark.read.csv(\"diabetes_prediction_dataset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show the content of the DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l8SSTzb2-Ij",
        "outputId": "bb84db5b-76e4-48d7-f223-188f8d24b5f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------------+-------------+---------------+-----+-----------+-------------------+--------+\n",
            "|gender| age|hypertension|heart_disease|smoking_history|  bmi|HbA1c_level|blood_glucose_level|diabetes|\n",
            "+------+----+------------+-------------+---------------+-----+-----------+-------------------+--------+\n",
            "|Female|80.0|           0|            1|          never|25.19|        6.6|                140|       0|\n",
            "|Female|54.0|           0|            0|        No Info|27.32|        6.6|                 80|       0|\n",
            "|  Male|28.0|           0|            0|          never|27.32|        5.7|                158|       0|\n",
            "|Female|36.0|           0|            0|        current|23.45|        5.0|                155|       0|\n",
            "|  Male|76.0|           1|            1|        current|20.14|        4.8|                155|       0|\n",
            "|Female|20.0|           0|            0|          never|27.32|        6.6|                 85|       0|\n",
            "|Female|44.0|           0|            0|          never|19.31|        6.5|                200|       1|\n",
            "|Female|79.0|           0|            0|        No Info|23.86|        5.7|                 85|       0|\n",
            "|  Male|42.0|           0|            0|          never|33.64|        4.8|                145|       0|\n",
            "|Female|32.0|           0|            0|          never|27.32|        5.0|                100|       0|\n",
            "|Female|53.0|           0|            0|          never|27.32|        6.1|                 85|       0|\n",
            "|Female|54.0|           0|            0|         former| 54.7|        6.0|                100|       0|\n",
            "|Female|78.0|           0|            0|         former|36.05|        5.0|                130|       0|\n",
            "|Female|67.0|           0|            0|          never|25.69|        5.8|                200|       0|\n",
            "|Female|76.0|           0|            0|        No Info|27.32|        5.0|                160|       0|\n",
            "|  Male|78.0|           0|            0|        No Info|27.32|        6.6|                126|       0|\n",
            "|  Male|15.0|           0|            0|          never|30.36|        6.1|                200|       0|\n",
            "|Female|42.0|           0|            0|          never|24.48|        5.7|                158|       0|\n",
            "|Female|42.0|           0|            0|        No Info|27.32|        5.7|                 80|       0|\n",
            "|  Male|37.0|           0|            0|           ever|25.72|        3.5|                159|       0|\n",
            "+------+----+------------+-------------+---------------+-----+-----------+-------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n"
      ],
      "metadata": {
        "id": "R9LXdK196tOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Dropping Duplicate Rows"
      ],
      "metadata": {
        "id": "nI1xdPH34S19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate rows\n",
        "df = df.dropDuplicates()\n",
        "\n",
        "# Show the count of records after dropping duplicates\n",
        "print(f\"Number of records after dropping duplicates: {df.count()}\")"
      ],
      "metadata": {
        "id": "Mzye3jId3Vj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf83572-8044-4938-d7be-67488d154c18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after dropping duplicates: 96146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Converting Categorical Labels into a Numerical Format"
      ],
      "metadata": {
        "id": "hmkgc9gs4ZSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Convert categorical labels (e.g., 'gender') to numerical format\n",
        "indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_indexed\")\n",
        "df = indexer.fit(df).transform(df)\n",
        "\n",
        "# Show the transformed DataFrame\n",
        "df.select(\"gender\", \"gender_indexed\").show(5)\n"
      ],
      "metadata": {
        "id": "T4zf8hb03zKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b6edcf-315b-46bf-b3e9-80673dba1e66"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------+\n",
            "|gender|gender_indexed|\n",
            "+------+--------------+\n",
            "|Female|           0.0|\n",
            "|  Male|           1.0|\n",
            "|Female|           0.0|\n",
            "|Female|           0.0|\n",
            "|Female|           0.0|\n",
            "+------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Handling Outliers for the 'age' Column"
      ],
      "metadata": {
        "id": "QkqjAI4B4c5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Ensure 'age' contains only integer values\n",
        "df = df.filter(col(\"age\").cast(\"int\").isNotNull())\n",
        "\n",
        "# Show the count of records after filtering\n",
        "print(f\"Number of records after handling age outliers: {df.count()}\")\n"
      ],
      "metadata": {
        "id": "7rwfGX0_4Nki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7145ca3-a45f-4d97-9625-34bd4101b08c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after handling age outliers: 96146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Handling Outliers for the 'BMI' Column Using IQR"
      ],
      "metadata": {
        "id": "Sjj-YLOA4g3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "# Calculate Q1 and Q3\n",
        "Q1 = df.approxQuantile(\"bmi\", [0.25], 0.01)[0]\n",
        "Q3 = df.approxQuantile(\"bmi\", [0.75], 0.01)[0]\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Calculate outlier boundaries\n",
        "lower_limit = Q1 - 1.5 * IQR\n",
        "upper_limit = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filter rows that are within the acceptable range\n",
        "df = df.filter((col(\"bmi\") >= lower_limit) & (col(\"bmi\") <= upper_limit))\n",
        "\n",
        "# Show the filtered DataFrame\n",
        "df.select(\"bmi\").show(5)"
      ],
      "metadata": {
        "id": "bNoEH4eg4oJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82828445-75dd-49bc-f70f-531e7e0edeba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|  bmi|\n",
            "+-----+\n",
            "|27.32|\n",
            "|27.32|\n",
            "| 21.7|\n",
            "|20.47|\n",
            "| 31.4|\n",
            "+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Filtering Rows with Invalid Biological Values"
      ],
      "metadata": {
        "id": "MLNtKZMO4sDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter((col(\"age\") > 1) & (col(\"bmi\") > 10) & (col(\"blood_glucose_level\") >= 80))\n",
        "\n",
        "# Show the filtered DataFrame\n",
        "df.select(\"age\", \"bmi\", \"blood_glucose_level\").show(5)"
      ],
      "metadata": {
        "id": "cHx7kK_Q4xwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4275bc53-8191-4a97-b0d6-fdd5ec8e1caf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-------------------+\n",
            "| age|  bmi|blood_glucose_level|\n",
            "+----+-----+-------------------+\n",
            "|21.0|27.32|                126|\n",
            "|26.0|27.32|                100|\n",
            "|49.0| 21.7|                158|\n",
            "|24.0|20.47|                100|\n",
            "|53.0| 31.4|                 85|\n",
            "+----+-----+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Checking for Inconsistent Data in Categorical Column"
      ],
      "metadata": {
        "id": "9_DguciE5AQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import initcap\n",
        "\n",
        "df = df.withColumn(\"smoking_history\", initcap(col(\"smoking_history\")))\n",
        "\n",
        "# Show the transformed DataFrame\n",
        "df.select(\"smoking_history\").show(5)"
      ],
      "metadata": {
        "id": "CaTT_vHn5A1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba40246-19b5-476f-d93f-1aa06d4c865f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|smoking_history|\n",
            "+---------------+\n",
            "|          Never|\n",
            "|          Never|\n",
            "|          Never|\n",
            "|         Former|\n",
            "|          Never|\n",
            "+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Handling missing values"
      ],
      "metadata": {
        "id": "bLE-EXGV5QdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, count, when, lit\n",
        "\n",
        "# Calculate the mode of 'smoking_history'\n",
        "mode_value = df.groupBy(\"smoking_history\").count().orderBy(col(\"count\").desc()).first()[0]\n",
        "\n",
        "# Replace 'No info' with the mode value\n",
        "df = df.withColumn(\"smoking_history\", when(col(\"smoking_history\") == \"No info\", lit(mode_value)).otherwise(col(\"smoking_history\")))\n",
        "\n",
        "# Show the modified DataFrame\n",
        "df.select(\"smoking_history\").show(5)"
      ],
      "metadata": {
        "id": "ct38yUiV5AiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efbc28e-cb53-41dc-c131-1862fb869f9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|smoking_history|\n",
            "+---------------+\n",
            "|          Never|\n",
            "|          Never|\n",
            "|          Never|\n",
            "|         Former|\n",
            "|          Never|\n",
            "+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Normalizing values"
      ],
      "metadata": {
        "id": "T-CWZhtd5bHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "\n",
        "# Assemble columns into a vector\n",
        "assembler = VectorAssembler(inputCols=[\"blood_glucose_level\", \"HbA1c_level\"], outputCol=\"features\")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Apply StandardScaler\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "scaler_model = scaler.fit(df)\n",
        "df = scaler_model.transform(df)\n",
        "\n",
        "# Show the scaled features\n",
        "df.select(\"scaled_features\").show(5)"
      ],
      "metadata": {
        "id": "sjxWMsCI5hBM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faaa1c00-6be5-45f4-89c6-f3a4b352da92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|     scaled_features|\n",
            "+--------------------+\n",
            "|[-0.2904463527940...|\n",
            "|[-0.9344938505553...|\n",
            "|[0.50222749060444...|\n",
            "|[-0.9344938505553...|\n",
            "|[-1.3060597146483...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Dropping Null Values"
      ],
      "metadata": {
        "id": "1ZfZCZJE5mj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with null values\n",
        "df = df.na.drop()\n",
        "\n",
        "# Show the count of records after dropping nulls\n",
        "print(f\"Number of records after dropping nulls: {df.count()}\")"
      ],
      "metadata": {
        "id": "RInWXabq5sfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa0d0a7-b2e1-473f-c30f-d591892d883c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after dropping nulls: 89595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Feature Engineering"
      ],
      "metadata": {
        "id": "FRKoofDY5vaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Define BMI categories\n",
        "df = df.withColumn(\"bmi_category\",\n",
        "                   when((col(\"bmi\") > 0) & (col(\"bmi\") <= 18.5), \"Underweight\")\n",
        "                   .when((col(\"bmi\") > 18.5) & (col(\"bmi\") <= 24.9), \"Normal\")\n",
        "                   .when((col(\"bmi\") > 24.9) & (col(\"bmi\") <= 29.9), \"Overweight\")\n",
        "                   .when((col(\"bmi\") > 29.9), \"Obese\"))\n",
        "\n",
        "# Show the categorized BMI column\n",
        "df.select(\"bmi\", \"bmi_category\").show(5)"
      ],
      "metadata": {
        "id": "FMG6FePn50Tb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a918fc62-84b4-49c2-ff1e-c72d6a87984b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+\n",
            "|  bmi|bmi_category|\n",
            "+-----+------------+\n",
            "|27.32|  Overweight|\n",
            "|27.32|  Overweight|\n",
            "| 21.7|      Normal|\n",
            "|20.47|      Normal|\n",
            "| 31.4|       Obese|\n",
            "+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "Do25OFrl57HQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3955bb-ec5f-46fe-8c5a-fa7cdee0a6bb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[gender: string, age: double, hypertension: int, heart_disease: int, smoking_history: string, bmi: double, HbA1c_level: double, blood_glucose_level: int, diabetes: int, gender_indexed: double, features: vector, scaled_features: vector, bmi_category: string]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithms/Visualizations"
      ],
      "metadata": {
        "id": "TK6_gxzxpYOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the Dataset"
      ],
      "metadata": {
        "id": "Z5QkJoNQqFbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=1234)"
      ],
      "metadata": {
        "id": "Ozbemm-TqH_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Logistic Regression"
      ],
      "metadata": {
        "id": "jaUEkXuHphI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "logistic_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# Train the model\n",
        "logistic_model = logistic_reg.fit(train_data)\n",
        "\n",
        "# Evaluate on test data\n",
        "predictions = logistic_model.transform(test_data)\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()\n"
      ],
      "metadata": {
        "id": "FyuYe-fppncC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}